{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11063799,"sourceType":"datasetVersion","datasetId":6893903}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:15:29.417126Z","iopub.execute_input":"2025-04-10T12:15:29.417407Z","iopub.status.idle":"2025-04-10T12:15:37.303671Z","shell.execute_reply.started":"2025-04-10T12:15:29.417377Z","shell.execute_reply":"2025-04-10T12:15:37.299481Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df= pd.read_csv(\"/kaggle/input/audio-files/Dataset/train_labels.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:16:02.388020Z","iopub.execute_input":"2025-04-10T12:16:02.388415Z","iopub.status.idle":"2025-04-10T12:16:02.436418Z","shell.execute_reply.started":"2025-04-10T12:16:02.388384Z","shell.execute_reply":"2025-04-10T12:16:02.435139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import librosa\n\ntime_series = []\nsample_rate = []\nfor idx in range(1500):\n    audio_path = \"/kaggle/input/audio-files/Dataset/train_folder/\" +str(idx+1) + \".wav\"\n    y, sr = librosa.load(audio_path, sr=None, mono=False)\n    time_series.append(y)\n    sample_rate.append(sr)\n\ndf[\"time_series\"] = time_series\ndf[\"sample_rate\"] = sample_rate\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:38:07.384787Z","iopub.execute_input":"2025-04-09T13:38:07.385158Z","iopub.status.idle":"2025-04-09T13:38:09.909008Z","shell.execute_reply.started":"2025-04-09T13:38:07.385127Z","shell.execute_reply":"2025-04-09T13:38:09.907378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder()\n\ndf['cluster'] = encoder.fit_transform(df[['category']])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:38:15.831552Z","iopub.execute_input":"2025-04-09T13:38:15.831877Z","iopub.status.idle":"2025-04-09T13:38:15.918936Z","shell.execute_reply.started":"2025-04-09T13:38:15.831853Z","shell.execute_reply":"2025-04-09T13:38:15.918056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import librosa\n\ncomp_df= pd.DataFrame()\ntime_series = []\nsample_rate = []\nfor idx in range(500):\n    audio_path = \"/kaggle/input/audio-files/Dataset/test_folder/\" +str(idx+1) + \".wav\"\n    y, sr = librosa.load(audio_path, sr=None, mono=False)\n    time_series.append(y)\n    sample_rate.append(sr)\n\ncomp_df[\"time_series\"] = time_series\ncomp_df[\"sample_rate\"] = sample_rate\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:16:08.704557Z","iopub.execute_input":"2025-04-10T12:16:08.704891Z","iopub.status.idle":"2025-04-10T12:16:23.595146Z","shell.execute_reply.started":"2025-04-10T12:16:08.704866Z","shell.execute_reply":"2025-04-10T12:16:23.594032Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature extraction and clustering","metadata":{}},{"cell_type":"code","source":"# Extracting mfcc features\n\nn_mfcc = 13\n\nMFCC= []\nDELTA_MFCC= []\nDELTA2_MFCC= []\nMFCC_MEAN= []\nMFCC_VAR= []\nDELTA_MFCC_MEAN= []\nDELTA_MFCC_VAR= []\nDELTA2_MFCC_MEAN= []\nDELTA2_MFCC_VAR= []\n\nfor idx in range(500):\n    y= comp_df.iloc[idx]['time_series']\n    sr= comp_df.iloc[idx]['sample_rate']\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n    MFCC.append(mfcc)\n    \n    delta_mfcc = librosa.feature.delta(mfcc)\n    DELTA_MFCC.append(delta_mfcc)\n    \n    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n    DELTA2_MFCC.append(delta2_mfcc)\n    \n    mfcc_mean = np.mean(mfcc, axis=1)\n    MFCC_MEAN.append(mfcc_mean)\n    \n    mfcc_var = np.var(mfcc, axis=1)\n    MFCC_VAR.append(mfcc_var)\n    \n    delta_mfcc_mean = np.mean(delta_mfcc, axis=1)\n    DELTA_MFCC_MEAN.append(delta_mfcc_mean)\n    \n    delta_mfcc_var = np.var(delta_mfcc, axis=1)\n    DELTA_MFCC_VAR.append(delta_mfcc_var)\n    \n    delta2_mfcc_mean = np.mean(delta2_mfcc, axis=1)\n    DELTA2_MFCC_MEAN.append(delta2_mfcc_mean)\n    \n    delta2_mfcc_var = np.var(delta2_mfcc, axis=1)\n    DELTA2_MFCC_VAR.append(delta2_mfcc_var)\n\ncomp_df[\"mfcc\"] = MFCC\ncomp_df[\"delta_mfcc\"] = DELTA_MFCC\ncomp_df[\"delta2_mfcc\"] = DELTA2_MFCC\ncomp_df[\"mfcc_mean\"] = MFCC_MEAN\ncomp_df[\"mfcc_var\"] = MFCC_VAR\ncomp_df[\"delta_mfcc_mean\"] = DELTA_MFCC_MEAN\ncomp_df[\"delta_mfcc_var\"] = DELTA_MFCC_VAR\ncomp_df[\"delta2_mfcc_mean\"] = DELTA2_MFCC_MEAN\ncomp_df[\"delta2_mfcc_var\"] = DELTA2_MFCC_VAR\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:16:51.665068Z","iopub.execute_input":"2025-04-10T12:16:51.665630Z","iopub.status.idle":"2025-04-10T12:17:16.839118Z","shell.execute_reply.started":"2025-04-10T12:16:51.665599Z","shell.execute_reply":"2025-04-10T12:17:16.837961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting time domain features\n\nrms_energy = []\nZCR = []\nfor idx in range(500):\n    y= comp_df.iloc[idx]['time_series']\n    sr= comp_df.iloc[idx]['sample_rate']\n    rms = librosa.feature.rms(y=y)\n    rms_energy.append(rms)\n    zcr = librosa.feature.zero_crossing_rate(y)\n    ZCR.append(zcr)\n    \ncomp_df[\"rms_energy\"] = rms_energy\ncomp_df[\"zcr\"] = ZCR\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:17:23.527046Z","iopub.execute_input":"2025-04-10T12:17:23.527635Z","iopub.status.idle":"2025-04-10T12:17:40.716745Z","shell.execute_reply.started":"2025-04-10T12:17:23.527598Z","shell.execute_reply":"2025-04-10T12:17:40.715667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting spectral features\n\nspectral_centroid = []\nspectral_bandwidth = []\nfor idx in range(500):\n    y= comp_df.iloc[idx]['time_series']\n    sr= comp_df.iloc[idx]['sample_rate']\n    s_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n    s_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n    spectral_centroid.append(s_centroid)\n    spectral_bandwidth.append(s_bandwidth)\n    \ncomp_df[\"spectral_centroid\"] = spectral_centroid\ncomp_df[\"spectral_bandwidth\"] = spectral_bandwidth\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:17:57.528325Z","iopub.execute_input":"2025-04-10T12:17:57.528807Z","iopub.status.idle":"2025-04-10T12:18:41.703067Z","shell.execute_reply.started":"2025-04-10T12:17:57.528768Z","shell.execute_reply":"2025-04-10T12:18:41.701947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting rhythmic features\n\nonset_rate = []\npulse_clarity= []\nfor idx in range(500):\n    y= comp_df.iloc[idx]['time_series']\n    sr= comp_df.iloc[idx]['sample_rate']\n    onset_r = librosa.onset.onset_strength(y=y, sr=sr)\n    onset_rate.append(onset_r)\n    p_clarity= librosa.beat.plp(y=y, sr=sr)\n    pulse_clarity.append(p_clarity)\n    \ncomp_df[\"pulse_clarity\"] = pulse_clarity\ncomp_df[\"onset_rate\"] = onset_rate\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:18:50.770245Z","iopub.execute_input":"2025-04-10T12:18:50.770588Z","iopub.status.idle":"2025-04-10T12:19:27.282524Z","shell.execute_reply.started":"2025-04-10T12:18:50.770564Z","shell.execute_reply":"2025-04-10T12:19:27.281580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features= list(comp_df.columns)\nfeatures.remove('time_series')\nfeatures.remove('sample_rate')\nfeatures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:19:30.973700Z","iopub.execute_input":"2025-04-10T12:19:30.974055Z","iopub.status.idle":"2025-04-10T12:19:30.981919Z","shell.execute_reply.started":"2025-04-10T12:19:30.974030Z","shell.execute_reply":"2025-04-10T12:19:30.980803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalising features using mean and variance\n\nimport numpy as np\n\nfor feat in features:\n    mean_col = np.stack(comp_df[feat])\n    mu = np.mean(mean_col, axis=0)\n    std = np.std(mean_col, axis=0)\n    \n    mean_col = (mean_col - mu) / std\n    mean_col= np.nan_to_num(mean_col, nan= 0)\n    comp_df[feat+\"_normalised\"] = mean_col.tolist()\n    \n\ncomp_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:19:48.460487Z","iopub.execute_input":"2025-04-10T12:19:48.460866Z","iopub.status.idle":"2025-04-10T12:19:49.627162Z","shell.execute_reply.started":"2025-04-10T12:19:48.460837Z","shell.execute_reply":"2025-04-10T12:19:49.625705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Flattening feature vectors\n\nimport numpy as np\nimport pandas as pd\n\n\nfeatures_1d = ['mfcc_mean_normalised', 'mfcc_var_normalised',\n       'delta_mfcc_mean_normalised', 'delta_mfcc_var_normalised',\n       'delta2_mfcc_mean_normalised', 'delta2_mfcc_var_normalised',\n        'pulse_clarity_normalised', 'onset_rate_normalised']\nfeatures_2d = ['mfcc_normalised', 'delta_mfcc_normalised',\n       'delta2_mfcc_normalised', 'zcr_normalised',\n        'rms_energy_normalised','spectral_centroid_normalised', 'spectral_bandwidth_normalised']\n\ncomp_df_exp = {}\n\nfor feat in features_1d:\n    arr = np.vstack(comp_df[feat].values)\n    for i in range(arr.shape[1]):\n        comp_df_exp[f'{feat}_{i}'] = arr[:, i] \n\nfor feat in features_2d:\n    arr = np.array(comp_df[feat].tolist())  \n    reshaped_arr = arr.reshape(arr.shape[0], -1)  \n    col_names = [f'{feat}_{i}_{j}' for i in range(arr.shape[1]) for j in range(arr.shape[2])]\n    \n    for j, col in enumerate(col_names):\n        comp_df_exp[col] = reshaped_arr[:, j]  \n\n\ncomp_df_exp = pd.DataFrame(comp_df_exp)\n\ncomp_df_exp.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:19:55.868659Z","iopub.execute_input":"2025-04-10T12:19:55.869039Z","iopub.status.idle":"2025-04-10T12:19:56.817501Z","shell.execute_reply.started":"2025-04-10T12:19:55.869008Z","shell.execute_reply":"2025-04-10T12:19:56.816120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# PCA on the features\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\npca = PCA(n_components=0.95)\ncomp_df_pca = pca.fit_transform(comp_df_exp)\n\ncomp_df_pca = pd.DataFrame(comp_df_pca, columns=[f'PC{i+1}' for i in range(comp_df_pca.shape[1])])\n\nexplained_variance = pca.explained_variance_ratio_\n\ncomp_df_pca.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:20:19.392278Z","iopub.execute_input":"2025-04-10T12:20:19.392793Z","iopub.status.idle":"2025-04-10T12:20:21.456436Z","shell.execute_reply.started":"2025-04-10T12:20:19.392745Z","shell.execute_reply":"2025-04-10T12:20:21.455273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comp_df_pca_red = comp_df_pca.iloc[:, :37]\ncomp_df_pca_red.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:20:26.270576Z","iopub.execute_input":"2025-04-10T12:20:26.270937Z","iopub.status.idle":"2025-04-10T12:20:26.294733Z","shell.execute_reply.started":"2025-04-10T12:20:26.270909Z","shell.execute_reply":"2025-04-10T12:20:26.293365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Self-implemented KMeans\n\nimport numpy as np\nimport pandas as pd\n\nclass DIY_KMeans:\n    def __init__(self, k, max_iters=100, tol=1e-4):\n        self.k = k\n        self.max_iters = max_iters\n        self.tol = tol\n        self.centroids = None\n    \n    def fit(self, X: pd.DataFrame):\n        n_samples = X.shape[0]\n        random_indices = np.random.choice(n_samples, self.k, replace=False)\n        self.centroids = X.iloc[random_indices].copy().reset_index(drop=True)\n        \n        for _ in range(self.max_iters):\n            labels = self._assign_clusters(X)\n            \n            new_centroids = X.groupby(labels).mean()\n            \n            if new_centroids.shape[0] < self.k:\n                break\n            \n            if np.linalg.norm(self.centroids.values - new_centroids.values) < self.tol:\n                break\n            \n            self.centroids = new_centroids.reset_index(drop=True)\n    \n    def _assign_clusters(self, X: pd.DataFrame):\n        distances = np.linalg.norm(X.values[:, np.newaxis] - self.centroids.values, axis=2)\n        return np.argmin(distances, axis=1)\n    \n    def predict(self, X: pd.DataFrame):\n        return self._assign_clusters(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:20:31.037837Z","iopub.execute_input":"2025-04-10T12:20:31.038227Z","iopub.status.idle":"2025-04-10T12:20:31.047245Z","shell.execute_reply.started":"2025-04-10T12:20:31.038194Z","shell.execute_reply":"2025-04-10T12:20:31.045832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generating predicted labels using self-implemented KMeans\n\nfrom sklearn.metrics import adjusted_rand_score\n\nkmeans = DIY_KMeans(k=50)\nkmeans.fit(comp_df_pca_red)\nfinal_labels= kmeans.predict(comp_df_pca_red)\nfinal_labels= pd.DataFrame(final_labels)\nfinal_labels = final_labels.rename(columns={0: \"cluster\"})\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:20:42.163502Z","iopub.execute_input":"2025-04-10T12:20:42.163861Z","iopub.status.idle":"2025-04-10T12:20:42.321547Z","shell.execute_reply.started":"2025-04-10T12:20:42.163832Z","shell.execute_reply":"2025-04-10T12:20:42.320550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels['id'] = df['filename'][0:500]\nfinal_labels.set_index('id',inplace=True)\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:20:50.451021Z","iopub.execute_input":"2025-04-10T12:20:50.451431Z","iopub.status.idle":"2025-04-10T12:20:50.462485Z","shell.execute_reply.started":"2025-04-10T12:20:50.451392Z","shell.execute_reply":"2025-04-10T12:20:50.460938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels.to_csv(\"output_1.csv\", index= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:21:01.598692Z","iopub.execute_input":"2025-04-10T12:21:01.599058Z","iopub.status.idle":"2025-04-10T12:21:01.610506Z","shell.execute_reply.started":"2025-04-10T12:21:01.599025Z","shell.execute_reply":"2025-04-10T12:21:01.609430Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## YAMNET to generate embeddings, followed by clustering","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow tensorflow_hub librosa numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:22:06.207690Z","iopub.execute_input":"2025-04-10T12:22:06.208040Z","iopub.status.idle":"2025-04-10T12:22:12.594153Z","shell.execute_reply.started":"2025-04-10T12:22:06.208014Z","shell.execute_reply":"2025-04-10T12:22:12.592699Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading YAMNET model\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport librosa\nimport numpy as np\n\nyamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:22:19.679322Z","iopub.execute_input":"2025-04-10T12:22:19.679945Z","iopub.status.idle":"2025-04-10T12:22:45.043571Z","shell.execute_reply.started":"2025-04-10T12:22:19.679890Z","shell.execute_reply":"2025-04-10T12:22:45.042487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generating embeddings using YAMNET\n\nfrom tqdm import tqdm\n\nscores = []\nembeddings = []\nspectrogram = []\n\nfor idx, x in tqdm(comp_df.iterrows(), total=len(comp_df), desc=\"Processing Audio\"):\n    score, embed, spect = yamnet_model(x['time_series'])  # Get YAMNet outputs\n    scores.append(score)\n    embeddings.append(embed)\n    spectrogram.append(spect)\n\ncomp_df['scores'] = scores\ncomp_df['embeddings'] = embeddings\ncomp_df['spectrogram'] = spectrogram\n\ncomp_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:23:11.731320Z","iopub.execute_input":"2025-04-10T12:23:11.731690Z","iopub.status.idle":"2025-04-10T12:24:23.289924Z","shell.execute_reply.started":"2025-04-10T12:23:11.731659Z","shell.execute_reply":"2025-04-10T12:24:23.288655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embed_df= comp_df[['embeddings', 'scores']]\nembed_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:24:41.990971Z","iopub.execute_input":"2025-04-10T12:24:41.991399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"arr = np.array(embed_df['embeddings'].apply(lambda x:x.numpy()).tolist())  \n\nmean = np.mean(arr, axis=0, keepdims=True)\nstd = np.std(arr, axis=0, keepdims=True)\nnormal_arr= (arr-mean)/std\n\nreshaped_arr = normal_arr.reshape(arr.shape[0], -1)  \n\ncol_names = [f'embeddings_{i}_{j}' for i in range(arr.shape[1]) for j in range(arr.shape[2])]\n\nembed_df_exp = {}\nfor j, col in enumerate(col_names):\n    embed_df_exp[col] = reshaped_arr[:, j]  \n\nembed_df_exp = pd.DataFrame(embed_df_exp)\nembed_df_exp.fillna(0, inplace=True)\nembed_df_exp.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:25:36.815073Z","iopub.execute_input":"2025-04-10T12:25:36.815609Z","iopub.status.idle":"2025-04-10T12:25:37.639663Z","shell.execute_reply.started":"2025-04-10T12:25:36.815548Z","shell.execute_reply":"2025-04-10T12:25:37.638621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Component reduction by PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\npca = PCA(n_components=0.95)\nembed_pca = pca.fit_transform(embed_df_exp)\n\nembed_pca = pd.DataFrame(embed_pca, columns=[f'PC{i+1}' for i in range(embed_pca.shape[1])])\n\nexplained_variance = pca.explained_variance_ratio_\n\nembed_pca","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:25:48.265865Z","iopub.execute_input":"2025-04-10T12:25:48.266235Z","iopub.status.idle":"2025-04-10T12:25:49.704417Z","shell.execute_reply.started":"2025-04-10T12:25:48.266204Z","shell.execute_reply":"2025-04-10T12:25:49.703207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# K-Means clustering using YAMNET embeddings post PCA\n\nkmeans = DIY_KMeans(k=50)\nkmeans.fit(embed_pca.iloc[:, :25])\nfinal_labels= kmeans.predict(embed_pca.iloc[:, :25])\nfinal_labels= pd.DataFrame(final_labels)\nfinal_labels = final_labels.rename(columns={0: \"cluster\"})\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:27:51.401470Z","iopub.execute_input":"2025-04-10T12:27:51.401846Z","iopub.status.idle":"2025-04-10T12:27:51.457129Z","shell.execute_reply.started":"2025-04-10T12:27:51.401816Z","shell.execute_reply":"2025-04-10T12:27:51.455902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels['id'] = df['filename'][0:500]\nfinal_labels.set_index('id',inplace=True)\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:29:18.802281Z","iopub.execute_input":"2025-04-10T12:29:18.802711Z","iopub.status.idle":"2025-04-10T12:29:18.816322Z","shell.execute_reply.started":"2025-04-10T12:29:18.802679Z","shell.execute_reply":"2025-04-10T12:29:18.815236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels.to_csv(\"output_2.csv\", index= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:29:21.887496Z","iopub.execute_input":"2025-04-10T12:29:21.887858Z","iopub.status.idle":"2025-04-10T12:29:21.894910Z","shell.execute_reply.started":"2025-04-10T12:29:21.887830Z","shell.execute_reply":"2025-04-10T12:29:21.893774Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Component reduction using T-SNE","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\ntsne = TSNE(n_components=2, perplexity=30, random_state=42)\nembed_tsne = tsne.fit_transform(embed_df_exp)\n\nembed_tsne = pd.DataFrame(embed_tsne, columns=['TSNE1', 'TSNE2'])\n\nembed_tsne","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:30:03.426527Z","iopub.execute_input":"2025-04-10T12:30:03.426889Z","iopub.status.idle":"2025-04-10T12:30:07.538272Z","shell.execute_reply.started":"2025-04-10T12:30:03.426864Z","shell.execute_reply":"2025-04-10T12:30:07.536418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# K-Means clustering using YAMNET embeddings post t-SNE\n\nkmeans = DIY_KMeans(k=50)\nkmeans.fit(embed_tsne)\nfinal_labels= kmeans.predict(embed_tsne)\nfinal_labels= pd.DataFrame(final_labels)\nfinal_labels = final_labels.rename(columns={0: \"cluster\"})\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:30:12.399251Z","iopub.execute_input":"2025-04-10T12:30:12.399761Z","iopub.status.idle":"2025-04-10T12:30:12.441200Z","shell.execute_reply.started":"2025-04-10T12:30:12.399713Z","shell.execute_reply":"2025-04-10T12:30:12.440177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels['id'] = df['filename'][0:500]\nfinal_labels.set_index('id',inplace=True)\nfinal_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:30:15.363796Z","iopub.execute_input":"2025-04-10T12:30:15.364157Z","iopub.status.idle":"2025-04-10T12:30:15.375305Z","shell.execute_reply.started":"2025-04-10T12:30:15.364128Z","shell.execute_reply":"2025-04-10T12:30:15.374144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_labels.to_csv(\"output_3.csv\", index= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:30:19.762040Z","iopub.execute_input":"2025-04-10T12:30:19.762495Z","iopub.status.idle":"2025-04-10T12:30:19.769293Z","shell.execute_reply.started":"2025-04-10T12:30:19.762463Z","shell.execute_reply":"2025-04-10T12:30:19.768039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CLAP Model","metadata":{}},{"cell_type":"code","source":"!pip install laion-clap torch librosa tqdm numpy pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:31:05.935269Z","iopub.execute_input":"2025-04-10T12:31:05.935709Z","iopub.status.idle":"2025-04-10T12:31:21.666006Z","shell.execute_reply.started":"2025-04-10T12:31:05.935673Z","shell.execute_reply":"2025-04-10T12:31:21.664683Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading pre-trained CLAP model and using it to classify test data\n\nfrom datasets import load_dataset\nfrom transformers import pipeline\nfrom tqdm import tqdm\n\nclass_labels= list(set(df['category']))\nresults= []\naudio_classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/larger_clap_general\")\nfor idx in tqdm(range(500), desc=\"Processing Audio Files\"):\n    audio_path = f\"/kaggle/input/audio-files/Dataset/test_folder/{idx+1}.wav\"\n    output = audio_classifier(audio_path, candidate_labels=class_labels)\n\n    #Assigning the label with maximum similarity score\n    predicted_label = max(output, key=lambda x: x[\"score\"])[\"label\"]\n\n    results.append({\"audio_file\": audio_path, \"predicted_label\": predicted_label})\n\nresults_df= pd.DataFrame(results)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:31:34.376778Z","iopub.execute_input":"2025-04-10T12:31:34.377165Z","iopub.status.idle":"2025-04-10T12:34:11.646851Z","shell.execute_reply.started":"2025-04-10T12:31:34.377135Z","shell.execute_reply":"2025-04-10T12:34:11.644329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df['id']= df['filename'][0:500]\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:06.127017Z","iopub.execute_input":"2025-04-07T18:46:06.127768Z","iopub.status.idle":"2025-04-07T18:46:06.148044Z","shell.execute_reply.started":"2025-04-07T18:46:06.127533Z","shell.execute_reply":"2025-04-07T18:46:06.146404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df= results_df.drop(['audio_file'], axis=1)\nresults_df= results_df.set_index(['id'])\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:11.772752Z","iopub.execute_input":"2025-04-07T18:46:11.773174Z","iopub.status.idle":"2025-04-07T18:46:11.786301Z","shell.execute_reply.started":"2025-04-07T18:46:11.773138Z","shell.execute_reply":"2025-04-07T18:46:11.785089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder()\n\nresults_df['cluster'] = encoder.fit_transform(results_df[['predicted_label']])\n\nresults_df= results_df.drop(['predicted_label'], axis=1)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:16.041515Z","iopub.execute_input":"2025-04-07T18:46:16.041931Z","iopub.status.idle":"2025-04-07T18:46:16.062293Z","shell.execute_reply.started":"2025-04-07T18:46:16.041895Z","shell.execute_reply":"2025-04-07T18:46:16.060854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df['cluster']= results_df['cluster'].astype(int)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:18.518927Z","iopub.execute_input":"2025-04-07T18:46:18.519364Z","iopub.status.idle":"2025-04-07T18:46:18.531482Z","shell.execute_reply.started":"2025-04-07T18:46:18.519327Z","shell.execute_reply":"2025-04-07T18:46:18.530126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.to_csv('output_4.csv', index= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:33.541748Z","iopub.execute_input":"2025-04-07T18:46:33.542229Z","iopub.status.idle":"2025-04-07T18:46:33.549780Z","shell.execute_reply.started":"2025-04-07T18:46:33.542196Z","shell.execute_reply":"2025-04-07T18:46:33.548484Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## AST Model (Best ARI score submission on Kaggle)","metadata":{}},{"cell_type":"code","source":"# Loading pre-trained AST model and using it to classify test data\n\nimport torch\nimport torchaudio\nimport pandas as pd\nfrom transformers import ASTFeatureExtractor, AutoModelForAudioClassification\nfrom tqdm import tqdm\n\n# Defining an audio feature extractor based on config.json file on git repo of the pretrained model\n\nextractor = ASTFeatureExtractor(\n    sampling_rate=16000,\n    num_mel_bins=128,\n    max_length=1024,\n    padding=\"max_length\",\n    return_attention_mask=True,\n    do_normalize=True,\n    feature_size=128\n)\n\n# Loading the model\n\nmodel = AutoModelForAudioClassification.from_pretrained(\"Evan-Lin/ast-esc50\")\nmodel.eval()\n\nclass_labels = list(model.config.id2label.values())\n\nresults = []\n\n# Generating label predictions\n\nfor idx in tqdm(range(500), desc=\"Processing with AST\"):\n    audio_path = f\"/kaggle/input/audio-files/Dataset/test_folder/{idx+1}.wav\"\n\n    try:\n        waveform, sample_rate = torchaudio.load(audio_path)\n        \n        if sample_rate != 16000:\n            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n            waveform = resampler(waveform)\n\n        if waveform.shape[0] > 1:\n            waveform = waveform.mean(dim=0, keepdim=True)\n\n        inputs = extractor(\n            waveform.squeeze().numpy(),\n            sampling_rate=16000,\n            return_tensors=\"pt\"\n        )\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n            logits = outputs.logits\n            pred_id = torch.argmax(logits, dim=-1).item()\n            predicted_label = model.config.id2label[pred_id]\n\n    except Exception as e:\n        print(f\"Error processing {audio_path}: {e}\")\n        predicted_label = \"ERROR\"\n\n    results.append({\"audio_file\": audio_path, \"predicted_label\": predicted_label})\n\nresults_df = pd.DataFrame(results)\nresults_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:52:31.014515Z","iopub.execute_input":"2025-04-09T13:52:31.014890Z","iopub.status.idle":"2025-04-09T14:14:37.512533Z","shell.execute_reply.started":"2025-04-09T13:52:31.014862Z","shell.execute_reply":"2025-04-09T14:14:37.511226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df['id']= df['filename'][0:500]\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T14:15:10.398432Z","iopub.execute_input":"2025-04-09T14:15:10.398826Z","iopub.status.idle":"2025-04-09T14:15:10.410300Z","shell.execute_reply.started":"2025-04-09T14:15:10.398797Z","shell.execute_reply":"2025-04-09T14:15:10.409205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ordinal encoding of labels\n\nimport pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder()\n\nresults_df['cluster'] = encoder.fit_transform(results_df[['predicted_label']])\n\nresults_df= results_df.drop(['predicted_label'], axis=1)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T14:15:22.240682Z","iopub.execute_input":"2025-04-09T14:15:22.241032Z","iopub.status.idle":"2025-04-09T14:15:22.259394Z","shell.execute_reply.started":"2025-04-09T14:15:22.241004Z","shell.execute_reply":"2025-04-09T14:15:22.258316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df['cluster']= results_df['cluster'].astype(int)\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T14:15:36.779415Z","iopub.execute_input":"2025-04-09T14:15:36.779840Z","iopub.status.idle":"2025-04-09T14:15:36.789731Z","shell.execute_reply.started":"2025-04-09T14:15:36.779811Z","shell.execute_reply":"2025-04-09T14:15:36.788643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df= results_df.drop(['audio_file'], axis=1)\nresults_df= results_df.set_index(['id'])\nresults_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T14:15:48.148468Z","iopub.execute_input":"2025-04-09T14:15:48.148858Z","iopub.status.idle":"2025-04-09T14:15:48.160430Z","shell.execute_reply.started":"2025-04-09T14:15:48.148824Z","shell.execute_reply":"2025-04-09T14:15:48.159145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.to_csv('output_5.csv', index= True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T14:16:00.523519Z","iopub.execute_input":"2025-04-09T14:16:00.523906Z","iopub.status.idle":"2025-04-09T14:16:00.536952Z","shell.execute_reply.started":"2025-04-09T14:16:00.523878Z","shell.execute_reply":"2025-04-09T14:16:00.535808Z"}},"outputs":[],"execution_count":null}]}